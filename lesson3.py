from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace
from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain.output_parsers import ResponseSchema, StructuredOutputParser
from langchain_core.output_parsers import StrOutputParser
import dotenv


dotenv.load_dotenv()
repo_id = "mistralai/Mistral-7B-Instruct-v0.3"

llm = HuggingFaceEndpoint(
    repo_id=repo_id,
    temperature=0.7,
    max_new_tokens=200,
    #frequency_penalty=1.2,
)

# 2. –õ–∞–Ω—Ü—é–≥ –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ç–µ–º–∏ –ø–∏—Ç–∞–Ω–Ω—è
response_schema = [
    ResponseSchema(name='question', description='–ü–∏—Ç–∞–Ω–Ω—è –∑–∞–¥–∞–Ω–µ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º'),
    ResponseSchema(name='topic', description="–ö–∞—Ç–µ–≥–æ—Ä—ñ—è –¥–æ —è–∫–æ—ó –Ω–∞–ª–µ–∂–∏—Ç—å –ø–∏—Ç–∞–Ω–Ω—è")
]

parser = StructuredOutputParser.from_response_schemas(response_schema)
format_instructions = parser.get_format_instructions()

topic_prompt = PromptTemplate.from_template(
    template="–í–∏–∑–Ω–∞—á, –¥–æ —è–∫–æ—ó –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó –Ω–∞–ª–µ–∂–∏—Ç—å —Ü–µ –ø–∏—Ç–∞–Ω–Ω—è: '{question}'. "
    "–í–∏–±–µ—Ä–∏ –æ–¥–Ω—É –∑: –ù–∞—É–∫–∞, –Ü—Å—Ç–æ—Ä—ñ—è, –¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó."
    "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É –Ω–∞—Å—Ç—É–ø–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ:\n{format_instructions}",
    partial_variables={"format_instructions": format_instructions}
)

topic_chain = topic_prompt | llm | parser


answer_prompt = PromptTemplate.from_template(
    "–î–∞–π –∫–æ—Ä–æ—Ç–∫—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è: {question}\n"
    "–ü–æ—Ä–µ–∫–æ–º–µ–Ω–¥—É–π —ñ–Ω—à—ñ —Ü—ñ–∫–∞–≤—ñ —Ç–µ–º–∏ –∑ {topic} —è–∫—ñ –ø–æ–≤'—è–∑–∞–Ω—ñ –∑ –ø–∏—Ç–∞–Ω–Ω—è–º {question}. –ù–∞–≤–µ–¥–∏ —Å–ø–∏—Å–æ–∫ –∑ 3-5 —Ä–µ—á–µ–π, –ª–∏—à–µ –Ω–∞–∑–≤–∏"
)

answer_chain = answer_prompt | llm | StrOutputParser()

chain = topic_chain | answer_chain

#print(chain.invoke({"question": "–ö–æ–ª–∏ –±—É–ª–∞ –≤–∏—Å–∞–¥–∫–∞ –Ω–∞ –º—ñ—Å—è—Ü—å?"}))



# -----------------------------------
# schemas = [
#     ResponseSchema(name="topic", description="–ö–∞—Ç–µ–≥–æ—Ä—ñ—è –ø–∏—Ç–∞–Ω–Ω—è (–ù–∞—É–∫–∞, –Ü—Å—Ç–æ—Ä—ñ—è, –¢–µ—Ö–Ω–æ–ª–æ–≥—ñ—ó)"),
#     ResponseSchema(name="short_answer", description="–ö–æ—Ä–æ—Ç–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è"),
#     ResponseSchema(name="long_answer", description="–†–æ–∑–≥–æ—Ä–Ω—É—Ç–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –ø–∏—Ç–∞–Ω–Ω—è"),
# ]
#
# # üîπ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ StructuredOutputParser
# output_parser = StructuredOutputParser.from_response_schemas(schemas)
# format_instructions = output_parser.get_format_instructions()
#
# # üîπ –°—Ç–≤–æ—Ä—é—î–º–æ –ø—Ä–æ–º–ø—Ç —ñ–∑ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è–º
# prompt = PromptTemplate(
#     template="–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É –Ω–∞—Å—Ç—É–ø–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ:\n{format_instructions}\n\n–ü–∏—Ç–∞–Ω–Ω—è: {question}",
#     input_variables=["question"],
#     partial_variables={"format_instructions": format_instructions},
# )
#
# # üîπ –õ–∞–Ω—Ü—é–≥ –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö
# chain = prompt | llm | output_parser
#
# # üîπ –¢–µ—Å—Ç—É—î–º–æ
# question = "–©–æ —Ç–∞–∫–µ –∫–≤–∞–Ω—Ç–æ–≤–∞ –º–µ—Ö–∞–Ω—ñ–∫–∞?"
# result = chain.invoke({"question": question})
#
# # üîπ –í–∏–≤–æ–¥–∏–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
# print(result)

# skills_schema = [
#     ResponseSchema(name="job_description", description="–û–ø–∏—Å –≤–∞–∫–∞–Ω—Å—ñ—ó"),
#     ResponseSchema(name="skills", description="–ö–ª—é—á–æ–≤—ñ –Ω–∞–≤–∏—á–∫–∏, –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –¥–ª—è –≤–∞–∫–∞–Ω—Å—ñ—ó")
# ]
#
# skills_parser = StructuredOutputParser.from_response_schemas(skills_schema)
# format_instructions = skills_parser.get_format_instructions()
#
# skills_prompt = PromptTemplate.from_template(
#     "–í–∏—Ç—è–≥–Ω–∏ –∫–ª—é—á–æ–≤—ñ –Ω–∞–≤–∏—á–∫–∏ –∑ –≤–∞–∫–∞–Ω—Å—ñ—ó: '{job_description}'.\n"
#     "–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É –Ω–∞—Å—Ç—É–ø–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ:\n{format_instructions}",
#     partial_variables={"format_instructions": format_instructions}
# )
#
# skills_chain = skills_prompt | llm | skills_parser
#
# # üîπ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∑—é–º–µ
# resume_prompt = PromptTemplate.from_template(
#     "–°–∫–ª–∞–¥–∏ —Ä–µ–∑—é–º–µ –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∑ —Ç–∞–∫–∏–º–∏ –Ω–∞–≤–∏—á–∫–∞–º–∏: {skills}.\n"
#     "–û–ø–∏—Å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞: {candidate_description}."
# )
#
# resume_chain = resume_prompt | llm | StrOutputParser()
#
# # üîπ –û–±'—î–¥–Ω–∞–Ω–∏–π –ª–∞–Ω—Ü—é–≥
# resume_generation_chain = skills_chain | resume_chain
#
# # üîπ –¢–µ—Å—Ç
# result = resume_generation_chain.invoke({
#     "job_description": "Python-—Ä–æ–∑—Ä–æ–±–Ω–∏–∫, –∑–Ω–∞–Ω–Ω—è Flask, SQL, Docker.",
#     "candidate_description": "3 —Ä–æ–∫–∏ –¥–æ—Å–≤—ñ–¥—É –≤ –±–µ–∫–µ–Ω–¥—ñ, —Ä–æ–∑—Ä–æ–±–∫–∞ REST API."
# })
# print(result)
